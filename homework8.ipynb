{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "history_visible": true,
      "mount_file_id": "1P8iUJk8CCkSiW4vsIznkxxoaTWnFmVaQ",
      "authorship_tag": "ABX9TyMRm02gZCSWeNFWPO5kKeSm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sangho-shane/JOB/blob/master/homework8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSIZE3NCUBX8"
      },
      "source": [
        "TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9PY5gmYUCLd",
        "outputId": "bb55f805-6401-45b1-917e-522320ce3619"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "data = [[1,2,3],[1,2,3,]]\n",
        "x_data = torch.tensor(data)\n",
        "print(x_data)\n",
        "\n",
        "np_array = np.array(data)\n",
        "print(np_array)\n",
        "x_np = torch.from_numpy(np_array)\n",
        "print(x_np)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3]])\n",
            "[[1 2 3]\n",
            " [1 2 3]]\n",
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC0IcQI7WESG",
        "outputId": "026ef8f3-6a16-4755-e37b-5d2a4059845c"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "shape = (3,5)\n",
        "x_rand = torch.rand(shape)\n",
        "print(x_rand)\n",
        "x_ones = torch.ones(shape)\n",
        "print(x_ones)\n",
        "x_zeros = torch.zeros(shape)\n",
        "print(x_zeros)\n",
        "print(x_rand[0])\n",
        "print(x_rand[0:2,0:2])\n",
        "x_rand[:1] = 0\n",
        "print(x_rand)\n",
        "x_rand[:,2]= 2\n",
        "print(x_rand)\n",
        "print(torch.cat([x_ones,x_zeros],dim=1))\n",
        "print(x_rand)\n",
        "print(torch.transpose(x_rand,0,1))\n",
        "print(x_ones.T)\n",
        "print('one',x_ones)\n",
        "print('zero',x_zeros)\n",
        "print('one * zero',x_ones * x_zeros)\n",
        "print('one @ zero',x_ones.T @ x_zeros)\n",
        "print('x_ones.sum()',x_ones.sum())\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6812, 0.2714, 0.4307, 0.9182, 0.4111],\n",
            "        [0.1301, 0.6241, 0.7997, 0.6680, 0.3181],\n",
            "        [0.2893, 0.2647, 0.8237, 0.9929, 0.0228]])\n",
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]])\n",
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n",
            "tensor([0.6812, 0.2714, 0.4307, 0.9182, 0.4111])\n",
            "tensor([[0.6812, 0.2714],\n",
            "        [0.1301, 0.6241]])\n",
            "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1301, 0.6241, 0.7997, 0.6680, 0.3181],\n",
            "        [0.2893, 0.2647, 0.8237, 0.9929, 0.0228]])\n",
            "tensor([[0.0000, 0.0000, 2.0000, 0.0000, 0.0000],\n",
            "        [0.1301, 0.6241, 2.0000, 0.6680, 0.3181],\n",
            "        [0.2893, 0.2647, 2.0000, 0.9929, 0.0228]])\n",
            "tensor([[1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.]])\n",
            "tensor([[0.0000, 0.0000, 2.0000, 0.0000, 0.0000],\n",
            "        [0.1301, 0.6241, 2.0000, 0.6680, 0.3181],\n",
            "        [0.2893, 0.2647, 2.0000, 0.9929, 0.0228]])\n",
            "tensor([[0.0000, 0.1301, 0.2893],\n",
            "        [0.0000, 0.6241, 0.2647],\n",
            "        [2.0000, 2.0000, 2.0000],\n",
            "        [0.0000, 0.6680, 0.9929],\n",
            "        [0.0000, 0.3181, 0.0228]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "one tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]])\n",
            "zero tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n",
            "one * zero tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n",
            "one @ zero tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n",
            "x_ones.sum() tensor(15.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAk5UsTcYzpF"
      },
      "source": [
        "# 새 섹션"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "83mU3hEhY5vF",
        "outputId": "3298c762-e739-41bd-b1fe-03206b0eb100"
      },
      "source": [
        "#homework 7\n",
        "# Songeui Kim. 2021/10/24\n",
        "# Word matching\n",
        "\n",
        "import math\n",
        "import random\n",
        "\n",
        "# read data\n",
        "filename = \"one_654.txt\"\n",
        "\n",
        "print(filename)\n",
        "file = open(filename, \"r\",encoding=\"utf8\")\n",
        "file.name\n",
        "data = []\n",
        "\n",
        "for i in file:\n",
        "    data.append(i.split())\n",
        "file.close()\n",
        "\n",
        "\n",
        "\n",
        "NFIRST = 21\n",
        "NLAST = 28\n",
        "NMIDDLE = 21\n",
        "\n",
        "\n",
        "PFIRST = 18 + 1\n",
        "PMIDDLE = 21\n",
        "PLAST = 7 + 1\n",
        "\n",
        "HanList = \\\n",
        "[['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ'],\\\n",
        "['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ'],\\\n",
        "[' ', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\\\n",
        "]\n",
        "\n",
        "HanphomeList = [\n",
        "['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ'], \\\n",
        "['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ'], \\\n",
        "['$','ㄱ', 'ㄴ', 'ㄷ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅇ'] \\\n",
        "]\n",
        "\n",
        "Hanmatrix = [[len(HanList[0]),len(HanList[1]),len(HanList[2])],[len(HanphomeList[0]),len(HanphomeList[1]),len(HanphomeList[2])]]\n",
        "\n",
        "\n",
        "def text_to_int_han(text): #한 글자로 초성 중성 종성 숫자찾기\n",
        "    uncoden = ord(text)\n",
        "    relpos = uncoden - int('0xAC00', 16) # (10588)\n",
        "    first = relpos // (NMIDDLE * NLAST) # (10588//(21*28)= 18, 즉 HanList[0][18] = ‘ㅎ’)\n",
        "    relpos = relpos % (NMIDDLE * NLAST) # (10588%(21*28) = 4)\n",
        "    middle = relpos // NLAST # (4//28 = 0, 즉, HanList[1][0]=‘ㅏ’)\n",
        "    last = relpos % NLAST # (4%28 = 4, Han[2][4] = ‘ㄴ’)\n",
        "    return [first,middle,last]\n",
        "#return [onehot(NFIRST,first), onehot(NMIDDLE,middle), onehot(NLAST,last)]\n",
        "\n",
        "def int_to_text_phome(a,b,c): #자음+모음+자음 숫자로 텍스트 자음+모음+자음 찾기 - hanphomelist\n",
        "    a = HanphomeList[0][a]\n",
        "    b = HanphomeList[1][b]\n",
        "    c = HanphomeList[2][c]\n",
        "    #print(a,b,c)\n",
        "    return str_to_text_han(a,b,c)\n",
        "\n",
        "def str_to_text_han(a,b,c): #자음+모음+자음 텍스트로 글자만들기 - hanlist\n",
        "    a = HanList[0].index(a, 0, NFIRST)\n",
        "    b = HanList[1].index(b, 0, NMIDDLE)\n",
        "    c = HanList[2].index(c.replace('$',' '), 0, NLAST)\n",
        "    #print(a, b, c)\n",
        "    return int_to_text_han(a,b,c)\n",
        "\n",
        "def int_to_text_han(a, b, c): #초성 중성 종성 숫자로 글자만들기 - hanlist\n",
        "    relpos = a * 588 + 28 * b + c\n",
        "    return chr(relpos + int('0xAC00', 16))\n",
        "\n",
        "def onehot(total,choice):\n",
        "    a = [0 for g in range(total)]\n",
        "    a[choice] = 1\n",
        "    return a\n",
        "\n",
        "def activate(a):\n",
        "    return max(a, 0)\n",
        "#return 1 / (1 + math.exp(-1 * a))\n",
        "\n",
        "\n",
        "def derivative(a):\n",
        "    if a > 0 :\n",
        "        return 1\n",
        "    else :\n",
        "        return 0\n",
        "#return a * (1 - a)\n",
        "\n",
        "\n",
        "def activate2(a):\n",
        "    return 1 / (1 + math.exp(-1 * a))\n",
        "\n",
        "\n",
        "def derivative2(a):\n",
        "    return a * (1 - a)\n",
        "\n",
        "def dehot(a):\n",
        "    return a.index(max(a),0,len(a))\n",
        "\n",
        "\n",
        "datas = []\n",
        "for i, j, k, l, m in data:\n",
        "    data2 = []\n",
        "    data3 = []\n",
        "    print(k,l,m)\n",
        "    k = HanphomeList[0].index(k, 0, PFIRST)\n",
        "    l = HanphomeList[1].index(l, 0, PMIDDLE)\n",
        "    m = HanphomeList[2].index(m, 0, PLAST)\n",
        "    data2.append(k)\n",
        "    data2.append(l)\n",
        "    data2.append(m)\n",
        "    data3 = [text_to_int_han(i)]\n",
        "    data3.append(data2)\n",
        "    data3.append([int(j)])\n",
        "    datas.append(data3)\n",
        "\n",
        "NI = Hanmatrix[0] # N of inputs\n",
        "NH = 50\n",
        "NO = Hanmatrix[1]\n",
        "N = len(datas[0])\n",
        "\n",
        "NEPOCH = 100\n",
        "LR = 0.1/N # learning rate 0.4/4\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# weight initialize\n",
        "woh = [[[random.uniform(-0.2, 0.2) for j in range(NH)] for g in range(NO[i])] for i in range(3)] # 3 * NO * NH\n",
        "whi = [[[random.uniform(-0.2, 0.2) for g in range(NI[i])] for j in range(NH)] for i in range(3)] # 3 * NH * NI\n",
        "\n",
        "o_bias = [[random.random() for i in range(NO[k])] for k in range(3)] # 3 * NO\n",
        "h_bias = [[random.random() for i in range(NH)] for k in range(3)] # 3 * NH\n",
        "\n",
        "ao = [[0.0 for i in range(NO[j])] for j in range(3)]\n",
        "ah = [[0.0 for i in range(NH)] for j in range(3)]\n",
        "do = [[0.0 for i in range(NO[j])] for j in range(3)]\n",
        "dh = [[0.0 for i in range(NH)] for j in range(3)]\n",
        "\n",
        "#training\n",
        "\n",
        "print(\"Start Training!\")\n",
        "print(\"Trainning...( 0 / \", (NEPOCH), \" ) -- hidden layer:\",NH)\n",
        "for x in range(NEPOCH):\n",
        "\n",
        "    # initialize\n",
        "    dwoh = [[[0.0 for j in range(NH)] for g in range(NO[i])] for i in range(3)] # 3 * NO * NH\n",
        "    dwhi = [[[0.0 for g in range(NI[i])] for j in range(NH)] for i in range(3)] # 3 * NH * NI\n",
        "    do_bias = [[0.0 for i in range(NO[k])] for k in range(3)]\n",
        "    dh_bias = [[0.0 for i in range(NH)] for k in range(3)]\n",
        "\n",
        "    for item in datas:\n",
        "        inputs = item[0]\n",
        "        label = item[1]\n",
        "        logs = item[2]\n",
        "        if 0.186022636658652*math.log(logs[0]+2) > random.uniform(0, 1):\n",
        "            for i in range(len(Hanmatrix[0])):\n",
        "                inputs2 = onehot(NI[i], inputs[i])\n",
        "                label2 = onehot(NO[i], label[i])\n",
        "                for j in range(NH):\n",
        "                    out = 0.0\n",
        "                    for k in range(NI[i]):\n",
        "                        out = out + whi[i][j][k] * inputs2[k]\n",
        "                    out = out + h_bias[i][j]\n",
        "                    #ao[j] = 1 / (1 + math.exp(-1 * out))\n",
        "                    #if out > 0:\n",
        "                    # ah[j]=out\n",
        "                    #else:\n",
        "                    # ah[j]=out*0.01\n",
        "                    ah[i][j] = activate(out)\n",
        "\n",
        "                for j in range(NO[i]):\n",
        "                    out = 0.0\n",
        "                    for k in range(NH):\n",
        "                        out = out + woh[i][j][k] * ah[i][k]\n",
        "                    out = out + o_bias[i][j]\n",
        "                    ao[i][j] = activate2(out)\n",
        "                    #ao[i][j] = out\n",
        "                for j in range(NO[i]):\n",
        "                    ao[i][j] = ao[i][j] / sum(ao[i])\n",
        "\n",
        "                ## backward\n",
        "                for j in range(NO[i]):\n",
        "                    do[i][j] = (label2[j] - ao[i][j]) * derivative2(ao[i][j])\n",
        "                    do_bias[i][j] = do_bias[i][j] + LR * do[i][j]\n",
        "                    for k in range(NH):\n",
        "                        dwoh[i][j][k] = dwoh[i][j][k] + LR * do[i][j] * ah[i][k]\n",
        "\n",
        "                for j in range(NH):\n",
        "                    total = 0.0\n",
        "                    for k in range(NO[i]):\n",
        "                        total = total + do[i][k] * woh[i][k][j]\n",
        "                    dh[i][j] = total * derivative(ah[i][j])\n",
        "                    dh_bias[i][j] = dh_bias[i][j] + LR * dh[i][j]\n",
        "                for j in range(NH):\n",
        "                    for k in range(NI[i]):\n",
        "                        dwhi[i][j][k] = dwhi[i][j][k] + LR * dh[i][j] * inputs2[k]\n",
        "\n",
        "    # update weight\n",
        "    for h in range(3):\n",
        "        for i in range(NH):\n",
        "            h_bias[h][i] = h_bias[h][i] + (1 / N) * dh_bias[h][i]\n",
        "            for j in range(NI[h]):\n",
        "                whi[h][i][j] = whi[h][i][j] + (1 / N) * dwhi[h][i][j]\n",
        "        for i in range(NO[h]):\n",
        "            o_bias[h][i] = o_bias[h][i] + (1 / N) * do_bias[h][i]\n",
        "            for j in range(NH):\n",
        "                woh[h][i][j] = woh[h][i][j] + (1 / N) * dwoh[h][i][j]\n",
        "    print(\"Trainning...(\", (x+1), '/', (NEPOCH), \")\")\n",
        "\n",
        "#prediction\n",
        "print(\"----Test----\")\n",
        "def predicts(a,b):\n",
        "    inserts = text_to_int_han(a)\n",
        "    for i in range(len(Hanmatrix[0])):\n",
        "        inputs2 = onehot(NI[i], inserts[i])\n",
        "        for j in range(NH):\n",
        "            out = 0.0\n",
        "            for k in range(NI[i]):\n",
        "                out = out + whi[i][j][k] * inputs2[k]\n",
        "            out = out + h_bias[i][j]\n",
        "            ah[i][j] = activate(out)\n",
        "\n",
        "        for j in range(NO[i]):\n",
        "            out = 0.0\n",
        "            for k in range(NH):\n",
        "                out = out + woh[i][j][k] * ah[i][k]\n",
        "            out = out + o_bias[i][j]\n",
        "            ao[i][j] = activate2(out)\n",
        "        for j in range(NO[i]):\n",
        "            ao[i][j] = ao[i][j] / sum(ao[i])\n",
        "\n",
        "    inputing = int_to_text_han(inserts[0], inserts[1], inserts[2])\n",
        "    outing = int_to_text_phome(int(round(dehot(ao[0]),0)),int(round(dehot(ao[1]),0)),int(round(dehot(ao[2]),0)))\n",
        "    print(\"input: \",inputing,\"(\",inserts[0], inserts[1], inserts[2],\"), predict: \",outing,\"(\",int(round(dehot(ao[0]),0)),int(round(dehot(ao[1]),0)),int(round(dehot(ao[2]),0)),\") label: \",b)\n",
        "\n",
        "\n",
        "for item in datas:\n",
        "    inputs = item[0]\n",
        "    label = item[1]\n",
        "    predicts(int_to_text_han(inputs[0],inputs[1],inputs[2]),int_to_text_phome(label[0],label[1],label[2]))\n",
        "\n",
        "\n",
        "\n",
        "# print \"After training, weight:\", weight"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one_654.txt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-d99657c1b11c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc0 in position 0: invalid start byte"
          ]
        }
      ]
    }
  ]
}